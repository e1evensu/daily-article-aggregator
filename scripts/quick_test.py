#!/usr/bin/env python3
"""
ä¸€é”®æµ‹è¯•è„šæœ¬ - æµ‹è¯•å…¨æµç¨‹æ˜¯å¦èƒ½è·‘é€š

ä½¿ç”¨æ–¹æ³•:
    python scripts/quick_test.py [--full] [--module MODULE]

å‚æ•°:
    --full      è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆåŒ…æ‹¬å®é™…æŠ“å–å’Œæ¨é€ï¼‰
    --module    åªæµ‹è¯•æŒ‡å®šæ¨¡å—: rss, analyzer, pusher, qa, stats, all
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import asyncio
from datetime import datetime


def print_header(title: str):
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def print_result(name: str, success: bool, message: str = ""):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    status = "âœ“ PASS" if success else "âœ— FAIL"
    print(f"  [{status}] {name}")
    if message:
        print(f"          {message}")


def test_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print_header("1. æµ‹è¯•æ¨¡å—å¯¼å…¥")
    
    modules = [
        ("src.config", "é…ç½®æ¨¡å—"),
        ("src.repository", "æ•°æ®ä»“åº“"),
        ("src.models", "æ•°æ®æ¨¡å‹"),
        ("src.fetchers", "æŠ“å–å™¨"),
        ("src.analyzers", "AIåˆ†æå™¨"),
        ("src.pushers", "æ¨é€å™¨"),
        ("src.qa", "QAé—®ç­”ç³»ç»Ÿ"),
        ("src.stats", "ç»Ÿè®¡åˆ†æ"),
        ("src.bots", "é£ä¹¦æœºå™¨äºº"),
        ("src.aggregation", "ä¸»é¢˜èšåˆ"),
    ]
    
    all_pass = True
    for module, desc in modules:
        try:
            __import__(module)
            print_result(desc, True)
        except Exception as e:
            print_result(desc, False, str(e)[:50])
            all_pass = False
    
    return all_pass


def test_config():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print_header("2. æµ‹è¯•é…ç½®åŠ è½½")
    
    try:
        from src.config import load_config
        config = load_config()
        
        # æ£€æŸ¥å…³é”®é…ç½®é¡¹
        checks = [
            ("database.path", config.get("database", {}).get("path")),
            ("openai.api_key", config.get("openai", {}).get("api_key")),
            ("feishu.webhook_url", config.get("feishu", {}).get("webhook_url")),
        ]
        
        all_pass = True
        for name, value in checks:
            has_value = bool(value and value != "your-xxx")
            print_result(name, has_value, "å·²é…ç½®" if has_value else "æœªé…ç½®æˆ–ä½¿ç”¨é»˜è®¤å€¼")
            if not has_value and name != "database.path":
                all_pass = False
        
        return all_pass
    except Exception as e:
        print_result("é…ç½®åŠ è½½", False, str(e)[:50])
        return False


def test_database():
    """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
    print_header("3. æµ‹è¯•æ•°æ®åº“")
    
    try:
        from src.repository import ArticleRepository
        from src.config import load_config
        
        config = load_config()
        db_path = config.get("database", {}).get("path", "data/articles.db")
        
        repo = ArticleRepository(db_path)
        repo.init_db()
        
        # æµ‹è¯•åŸºæœ¬æ“ä½œ
        articles = repo.get_all_articles()
        unpushed = repo.get_unpushed_articles()
        
        print_result("æ•°æ®åº“è¿æ¥", True)
        print_result(f"æ–‡ç« æ€»æ•°: {len(articles)}", True)
        print_result(f"å¾…æ¨é€: {len(unpushed)}", True)
        
        repo.close()
        return True
    except Exception as e:
        print_result("æ•°æ®åº“", False, str(e)[:50])
        return False


def test_rss_fetcher():
    """æµ‹è¯•RSSæŠ“å–"""
    print_header("4. æµ‹è¯•RSSæŠ“å–")
    
    try:
        from src.fetchers.rss_fetcher import RSSFetcher
        
        fetcher = RSSFetcher()
        
        # æµ‹è¯•è§£æOPML
        opml_files = list(Path("rss").glob("*.opml"))
        print_result(f"å‘ç° {len(opml_files)} ä¸ªOPMLæ–‡ä»¶", len(opml_files) > 0)
        
        return True
    except Exception as e:
        print_result("RSSæŠ“å–", False, str(e)[:50])
        return False


def test_atum_blog_fetcher():
    """æµ‹è¯•Atumåšå®¢æŠ“å–"""
    print_header("4.1 æµ‹è¯•Atumåšå®¢æŠ“å–")
    
    try:
        from src.fetchers.web_blog_fetcher import AtumBlogFetcher
        
        fetcher = AtumBlogFetcher({'enabled': True, 'timeout': 30, 'days_back': 365})
        result = fetcher.fetch()
        
        print_result(f"æŠ“å–åˆ° {len(result.items)} ç¯‡æ–‡ç« ", len(result.items) >= 0)
        
        if result.items:
            print(f"          æœ€æ–°: {result.items[0].get('title', 'N/A')[:40]}...")
        
        if result.error:
            print(f"          é”™è¯¯: {result.error[:50]}")
        
        return len(result.items) > 0 or result.error is None
    except Exception as e:
        print_result("Atumåšå®¢æŠ“å–", False, str(e)[:50])
        return False


def test_ai_analyzer():
    """æµ‹è¯•AIåˆ†æå™¨"""
    print_header("5. æµ‹è¯•AIåˆ†æå™¨")
    
    try:
        from src.analyzers.ai_analyzer import AIAnalyzer
        from src.config import load_config
        
        config = load_config()
        api_key = config.get("openai", {}).get("api_key")
        
        if not api_key or api_key == "your-openai-api-key":
            print_result("AIåˆ†æå™¨", False, "æœªé…ç½®OpenAI API Key")
            return False
        
        analyzer = AIAnalyzer(api_key)
        print_result("AIåˆ†æå™¨åˆå§‹åŒ–", True)
        
        # æµ‹è¯•åˆ†æï¼ˆå¯é€‰ï¼‰
        test_content = "This is a test article about cybersecurity vulnerabilities."
        result = asyncio.run(analyzer.analyze(test_content))
        print_result("AIåˆ†ææµ‹è¯•", bool(result))
        
        return True
    except Exception as e:
        print_result("AIåˆ†æå™¨", False, str(e)[:50])
        return False


def test_qa_system():
    """æµ‹è¯•QAé—®ç­”ç³»ç»Ÿ"""
    print_header("6. æµ‹è¯•QAé—®ç­”ç³»ç»Ÿ")
    
    try:
        from src.qa import QAEngine, KnowledgeBase, EmbeddingService
        from src.qa.enhanced_retriever import EnhancedRetriever
        from src.qa.history_aware_query_builder import HistoryAwareQueryBuilder
        
        print_result("QAEngine å¯¼å…¥", True)
        print_result("KnowledgeBase å¯¼å…¥", True)
        print_result("EmbeddingService å¯¼å…¥", True)
        print_result("EnhancedRetriever å¯¼å…¥", True)
        print_result("HistoryAwareQueryBuilder å¯¼å…¥", True)
        
        return True
    except Exception as e:
        print_result("QAç³»ç»Ÿ", False, str(e)[:50])
        return False


def test_stats_system():
    """æµ‹è¯•ç»Ÿè®¡åˆ†æç³»ç»Ÿ"""
    print_header("7. æµ‹è¯•ç»Ÿè®¡åˆ†æç³»ç»Ÿ")
    
    try:
        from src.stats import (
            StatsCollector, StatsStore, StatsAggregator,
            TopicTracker, StatsAPI
        )
        
        # æµ‹è¯•åˆå§‹åŒ–
        store = StatsStore(":memory:")
        collector = StatsCollector(store)
        aggregator = StatsAggregator(store)
        
        print_result("StatsStore åˆå§‹åŒ–", True)
        print_result("StatsCollector åˆå§‹åŒ–", True)
        print_result("StatsAggregator åˆå§‹åŒ–", True)
        
        # æµ‹è¯•è®°å½•äº‹ä»¶
        collector.record_query("test query", 0.5, 3)
        stats = aggregator.get_daily_stats()
        print_result("äº‹ä»¶è®°å½•å’Œèšåˆ", True)
        
        return True
    except Exception as e:
        print_result("ç»Ÿè®¡ç³»ç»Ÿ", False, str(e)[:50])
        return False


def test_feishu_bot():
    """æµ‹è¯•é£ä¹¦æœºå™¨äºº"""
    print_header("8. æµ‹è¯•é£ä¹¦æœºå™¨äºº")
    
    try:
        from src.bots import FeishuBot, FeishuEventHandler, ThreadReplier
        from src.config import load_config
        
        config = load_config()
        webhook_url = config.get("feishu", {}).get("webhook_url")
        
        print_result("FeishuBot å¯¼å…¥", True)
        print_result("FeishuEventHandler å¯¼å…¥", True)
        print_result("ThreadReplier å¯¼å…¥", True)
        
        if webhook_url and webhook_url != "your-feishu-webhook-url":
            print_result("Webhook URL å·²é…ç½®", True)
        else:
            print_result("Webhook URL", False, "æœªé…ç½®")
        
        return True
    except Exception as e:
        print_result("é£ä¹¦æœºå™¨äºº", False, str(e)[:50])
        return False


def test_sitemap_importer():
    """æµ‹è¯•Sitemapå¯¼å…¥å™¨"""
    print_header("9. æµ‹è¯•Sitemapå¯¼å…¥å™¨")
    
    try:
        from src.fetchers.sitemap_importer import (
            SitemapParser, CrawlRuleEngine, IncrementalCrawler,
            HTMLToMarkdownConverter, SitemapImporter
        )
        
        print_result("SitemapParser å¯¼å…¥", True)
        print_result("CrawlRuleEngine å¯¼å…¥", True)
        print_result("IncrementalCrawler å¯¼å…¥", True)
        print_result("HTMLToMarkdownConverter å¯¼å…¥", True)
        print_result("SitemapImporter å¯¼å…¥", True)
        
        return True
    except Exception as e:
        print_result("Sitemapå¯¼å…¥å™¨", False, str(e)[:50])
        return False


def run_full_test():
    """è¿è¡Œå®Œæ•´æµç¨‹æµ‹è¯•"""
    print_header("å®Œæ•´æµç¨‹æµ‹è¯•")
    
    try:
        from src.config import load_config
        from src.repository import ArticleRepository
        from src.fetchers.rss_fetcher import RSSFetcher
        
        config = load_config()
        db_path = config.get("database", {}).get("path", "data/articles.db")
        
        # 1. åˆå§‹åŒ–
        repo = ArticleRepository(db_path)
        repo.init_db()
        fetcher = RSSFetcher()
        
        # 2. æŠ“å–æ–‡ç« 
        print("\n  æ­£åœ¨æŠ“å–RSS...")
        articles = asyncio.run(fetcher.fetch_feed("https://atum.li/cn/feed.xml"))
        print(f"  æŠ“å–åˆ° {len(articles)} ç¯‡æ–‡ç« ")
        
        # 3. ä¿å­˜åˆ°æ•°æ®åº“
        saved = 0
        for article in articles[:3]:  # åªä¿å­˜å‰3ç¯‡æµ‹è¯•
            if not repo.exists_by_url(article.get("url", "")):
                try:
                    repo.save_article(article)
                    saved += 1
                except:
                    pass
        
        print(f"  æ–°ä¿å­˜ {saved} ç¯‡æ–‡ç« ")
        
        # 4. ç»Ÿè®¡
        total = len(repo.get_all_articles())
        unpushed = len(repo.get_unpushed_articles())
        print(f"  æ•°æ®åº“æ€»è®¡: {total} ç¯‡, å¾…æ¨é€: {unpushed} ç¯‡")
        
        repo.close()
        print_result("å®Œæ•´æµç¨‹æµ‹è¯•", True)
        return True
        
    except Exception as e:
        print_result("å®Œæ•´æµç¨‹æµ‹è¯•", False, str(e))
        return False


def print_summary(results: dict):
    """æ‰“å°æµ‹è¯•æ€»ç»“"""
    print_header("æµ‹è¯•æ€»ç»“")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    print(f"\n  é€šè¿‡: {passed}/{total}")
    print(f"  æˆåŠŸç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\n  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
    else:
        print("\n  âš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        failed = [k for k, v in results.items() if not v]
        print(f"  å¤±è´¥é¡¹: {', '.join(failed)}")


def main():
    parser = argparse.ArgumentParser(description="ä¸€é”®æµ‹è¯•è„šæœ¬")
    parser.add_argument("--full", action="store_true", help="è¿è¡Œå®Œæ•´æµ‹è¯•")
    parser.add_argument("--module", type=str, help="åªæµ‹è¯•æŒ‡å®šæ¨¡å—")
    args = parser.parse_args()
    
    print("\n" + "=" * 60)
    print("  Daily Article Aggregator - ä¸€é”®æµ‹è¯•")
    print(f"  æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    results = {}
    
    # åŸºç¡€æµ‹è¯•
    results["æ¨¡å—å¯¼å…¥"] = test_imports()
    results["é…ç½®åŠ è½½"] = test_config()
    results["æ•°æ®åº“"] = test_database()
    
    # åŠŸèƒ½æ¨¡å—æµ‹è¯•
    if not args.module or args.module in ["rss", "all"]:
        results["RSSæŠ“å–"] = test_rss_fetcher()
        results["Atumåšå®¢"] = test_atum_blog_fetcher()
    
    if not args.module or args.module in ["analyzer", "all"]:
        results["AIåˆ†æå™¨"] = test_ai_analyzer()
    
    if not args.module or args.module in ["qa", "all"]:
        results["QAç³»ç»Ÿ"] = test_qa_system()
    
    if not args.module or args.module in ["stats", "all"]:
        results["ç»Ÿè®¡ç³»ç»Ÿ"] = test_stats_system()
    
    if not args.module or args.module in ["pusher", "all"]:
        results["é£ä¹¦æœºå™¨äºº"] = test_feishu_bot()
        results["Sitemapå¯¼å…¥"] = test_sitemap_importer()
    
    # å®Œæ•´æµç¨‹æµ‹è¯•
    if args.full:
        results["å®Œæ•´æµç¨‹"] = run_full_test()
    
    print_summary(results)
    
    return 0 if all(results.values()) else 1


if __name__ == "__main__":
    sys.exit(main())
