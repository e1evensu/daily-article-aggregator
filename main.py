#!/usr/bin/env python3
"""
æ¯æ—¥æ–‡ç« èšåˆå™¨ - ä¸»ç¨‹åºå…¥å£
Daily Article Aggregator - Main Entry Point

# SQLite ç‰ˆæœ¬å…¼å®¹æ€§è¡¥ä¸ - ChromaDB éœ€è¦ SQLite >= 3.35.0
try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

æ”¯æŒä¸‰ç§è¿è¡Œæ¨¡å¼ï¼š
1. å®šæ—¶è°ƒåº¦æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰ï¼šæ¯å¤©åœ¨é…ç½®çš„æ—¶é—´è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡
2. å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼ˆ--onceï¼‰ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡åé€€å‡º
3. RSSè¯„ä¼°æ¨¡å¼ï¼ˆ--evaluateï¼‰ï¼šè¯„ä¼°RSSè®¢é˜…æºè´¨é‡

ä½¿ç”¨æ–¹æ³• Usage:
    # å¯åŠ¨å®šæ—¶è°ƒåº¦
    python main.py
    
    # å•æ¬¡æ‰§è¡Œ
    python main.py --once
    
    # è¯„ä¼°RSSæº
    python main.py --evaluate --opml feeds.opml
    
    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
    python main.py --config my_config.yaml --once

éœ€æ±‚ 7.5: æ”¯æŒå‘½ä»¤è¡Œå‚æ•°æ§åˆ¶
"""

import argparse
import logging
import os
import sys
from pathlib import Path

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.config import load_config
from src.scheduler import Scheduler

# Import new components for advanced features
try:
    from src.fetchers.dblp_fetcher import DBLPFetcher
    from src.fetchers.nvd_fetcher import NVDFetcher
    from src.fetchers.kev_fetcher import KEVFetcher
    from src.fetchers.huggingface_fetcher import HuggingFaceFetcher
    from src.fetchers.pwc_fetcher import PWCFetcher
    from src.fetchers.blog_fetcher import BlogFetcher
    from src.filters.vulnerability_filter import VulnerabilityFilter
    from src.scoring.priority_scorer import PriorityScorer
    from src.pushers.tiered_pusher import TieredPusher
    ADVANCED_FEATURES_AVAILABLE = True
except ImportError:
    ADVANCED_FEATURES_AVAILABLE = False


# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'


def setup_logging(verbose: bool = False) -> None:
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿ
    Setup logging system
    
    Args:
        verbose: æ˜¯å¦å¯ç”¨è¯¦ç»†æ—¥å¿—ï¼ˆDEBUGçº§åˆ«ï¼‰
                 Whether to enable verbose logging (DEBUG level)
    """
    level = logging.DEBUG if verbose else logging.INFO
    
    logging.basicConfig(
        level=level,
        format=LOG_FORMAT,
        datefmt=LOG_DATE_FORMAT,
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # é™ä½ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
    # Reduce log level for third-party libraries
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('httpx').setLevel(logging.WARNING)
    logging.getLogger('httpcore').setLevel(logging.WARNING)
    logging.getLogger('openai').setLevel(logging.WARNING)
    logging.getLogger('schedule').setLevel(logging.WARNING)


def parse_args() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°
    Parse command line arguments
    
    Returns:
        è§£æåçš„å‚æ•°å‘½åç©ºé—´
        Parsed arguments namespace
    """
    parser = argparse.ArgumentParser(
        description='æ¯æ—¥æ–‡ç« èšåˆå™¨ - è‡ªåŠ¨åŒ–å†…å®¹èšåˆå’Œåˆ†æç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
è¿è¡Œæ¨¡å¼ Modes:
  é»˜è®¤æ¨¡å¼    å¯åŠ¨å®šæ—¶è°ƒåº¦ï¼Œæ¯å¤©åœ¨é…ç½®çš„æ—¶é—´è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡
  --once      å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼Œç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡åé€€å‡º
  --evaluate  RSSè¯„ä¼°æ¨¡å¼ï¼Œè¯„ä¼°è®¢é˜…æºè´¨é‡å¹¶ç”ŸæˆæŠ¥å‘Š

ç¤ºä¾‹ Examples:
  # å¯åŠ¨å®šæ—¶è°ƒåº¦ï¼ˆæ¯å¤©åœ¨config.yamlä¸­é…ç½®çš„æ—¶é—´æ‰§è¡Œï¼‰
  python main.py
  
  # ç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡
  python main.py --once
  
  # è¯„ä¼°RSSè®¢é˜…æºè´¨é‡
  python main.py --evaluate --opml feeds.opml
  
  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python main.py --config my_config.yaml --once
  
  # å¯ç”¨è¯¦ç»†æ—¥å¿—
  python main.py --once --verbose
        """
    )
    
    # è¿è¡Œæ¨¡å¼å‚æ•°
    mode_group = parser.add_argument_group('è¿è¡Œæ¨¡å¼ Mode Options')
    mode_group.add_argument(
        '--once', '-1',
        action='store_true',
        help='å•æ¬¡æ‰§è¡Œæ¨¡å¼ï¼šç«‹å³æ‰§è¡Œä¸€æ¬¡ä»»åŠ¡åé€€å‡º / Run task once and exit'
    )
    mode_group.add_argument(
        '--evaluate', '-e',
        action='store_true',
        help='RSSè¯„ä¼°æ¨¡å¼ï¼šè¯„ä¼°è®¢é˜…æºè´¨é‡ / Run RSS feed evaluation mode'
    )
    mode_group.add_argument(
        '--checkpoint-status',
        action='store_true',
        help='æŸ¥çœ‹æ–­ç‚¹ç»­ä¼ çŠ¶æ€ / Show checkpoint status'
    )
    mode_group.add_argument(
        '--clear-checkpoint',
        action='store_true',
        help='æ¸…é™¤æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹ / Clear checkpoint files'
    )
    
    # é…ç½®å‚æ•°
    config_group = parser.add_argument_group('é…ç½®é€‰é¡¹ Config Options')
    config_group.add_argument(
        '--config', '-c',
        type=str,
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml) / Config file path (default: config.yaml)'
    )
    config_group.add_argument(
        '--env',
        type=str,
        default=None,
        help='.envæ–‡ä»¶è·¯å¾„ (é»˜è®¤: è‡ªåŠ¨æŸ¥æ‰¾) / .env file path (default: auto-discover)'
    )
    
    # è¯„ä¼°æ¨¡å¼å‚æ•°
    eval_group = parser.add_argument_group('è¯„ä¼°æ¨¡å¼é€‰é¡¹ Evaluation Options (ä»…ç”¨äº --evaluate)')
    eval_group.add_argument(
        '--opml',
        type=str,
        default=None,
        help='OPMLæ–‡ä»¶è·¯å¾„ (é»˜è®¤: ä»é…ç½®æ–‡ä»¶è¯»å–) / OPML file path (default: from config)'
    )
    eval_group.add_argument(
        '--output', '-O',
        type=str,
        default='reports',
        help='è¯„ä¼°æŠ¥å‘Šè¾“å‡ºç›®å½• (é»˜è®¤: reports) / Output directory for reports (default: reports)'
    )
    eval_group.add_argument(
        '--min-score',
        type=float,
        default=0.6,
        help='æœ€ä½è´¨é‡è¯„åˆ†é˜ˆå€¼ (é»˜è®¤: 0.6) / Minimum quality score threshold (default: 0.6)'
    )
    
    # é€šç”¨å‚æ•°
    general_group = parser.add_argument_group('é€šç”¨é€‰é¡¹ General Options')
    general_group.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='å¯ç”¨è¯¦ç»†æ—¥å¿—è¾“å‡º / Enable verbose logging'
    )
    
    return parser.parse_args()


def run_scheduled_mode(config: dict, logger: logging.Logger) -> int:
    """
    è¿è¡Œå®šæ—¶è°ƒåº¦æ¨¡å¼
    Run scheduled mode
    
    Args:
        config: é…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        é€€å‡ºç 
    """
    logger.info("å¯åŠ¨å®šæ—¶è°ƒåº¦æ¨¡å¼...")
    logger.info(f"ä»»åŠ¡å°†åœ¨æ¯å¤© {config.get('schedule', {}).get('time', '09:00')} æ‰§è¡Œ")
    
    try:
        scheduler = Scheduler(config)
        scheduler.start()
        return 0
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºé€€å‡º")
        return 0
    except Exception as e:
        logger.error(f"è°ƒåº¦å™¨è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        return 1


def show_checkpoint_status(config: dict, logger: logging.Logger) -> int:
    """
    æ˜¾ç¤ºæ–­ç‚¹ç»­ä¼ çŠ¶æ€
    Show checkpoint status
    
    Args:
        config: é…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        é€€å‡ºç 
    """
    try:
        from src.utils.checkpoint import CheckpointManager
    except ImportError:
        print("é”™è¯¯: æ–­ç‚¹ç»­ä¼ æ¨¡å—ä¸å¯ç”¨")
        return 1
    
    checkpoint_config = config.get('checkpoint', {})
    checkpoint_dir = checkpoint_config.get('dir', 'data/checkpoints')
    
    manager = CheckpointManager(checkpoint_dir=checkpoint_dir)
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    fetch_cp = manager.load_fetch_checkpoint()
    process_cp = manager.load_process_checkpoint()
    
    print(f"\n{'='*60}")
    print("æ–­ç‚¹ç»­ä¼ çŠ¶æ€")
    print(f"{'='*60}")
    print(f"æ£€æŸ¥ç‚¹ç›®å½•: {checkpoint_dir}")
    print()
    
    if fetch_cp:
        print("ğŸ“¥ æŠ“å–é˜¶æ®µæ£€æŸ¥ç‚¹:")
        print(f"   ID: {fetch_cp.checkpoint_id}")
        print(f"   åˆ›å»ºæ—¶é—´: {fetch_cp.created_at}")
        print(f"   æ›´æ–°æ—¶é—´: {fetch_cp.updated_at}")
        print(f"   çŠ¶æ€: {fetch_cp.phase}")
        print(f"   è¿›åº¦: {len(fetch_cp.completed_feeds)}/{fetch_cp.total_feeds} ä¸ªè®¢é˜…æº")
        print(f"   å¤±è´¥: {len(fetch_cp.failed_feeds)} ä¸ªè®¢é˜…æº")
        total_articles = sum(len(a) for a in fetch_cp.fetched_articles.values())
        print(f"   å·²æŠ“å–æ–‡ç« : {total_articles} ç¯‡")
    else:
        print("ğŸ“¥ æŠ“å–é˜¶æ®µæ£€æŸ¥ç‚¹: æ— ")
    
    print()
    
    if process_cp:
        print("âš™ï¸  å¤„ç†é˜¶æ®µæ£€æŸ¥ç‚¹:")
        print(f"   ID: {process_cp.checkpoint_id}")
        print(f"   åˆ›å»ºæ—¶é—´: {process_cp.created_at}")
        print(f"   æ›´æ–°æ—¶é—´: {process_cp.updated_at}")
        print(f"   çŠ¶æ€: {process_cp.phase}")
        print(f"   è¿›åº¦: {len(process_cp.processed_urls)}/{process_cp.total_articles} ç¯‡æ–‡ç« ")
        print(f"   å¤±è´¥: {len(process_cp.failed_urls)} ç¯‡æ–‡ç« ")
    else:
        print("âš™ï¸  å¤„ç†é˜¶æ®µæ£€æŸ¥ç‚¹: æ— ")
    
    print(f"\n{'='*60}\n")
    
    return 0


def clear_checkpoint(config: dict, logger: logging.Logger) -> int:
    """
    æ¸…é™¤æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹
    Clear checkpoint files
    
    Args:
        config: é…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        é€€å‡ºç 
    """
    try:
        from src.utils.checkpoint import CheckpointManager
    except ImportError:
        print("é”™è¯¯: æ–­ç‚¹ç»­ä¼ æ¨¡å—ä¸å¯ç”¨")
        return 1
    
    checkpoint_config = config.get('checkpoint', {})
    checkpoint_dir = checkpoint_config.get('dir', 'data/checkpoints')
    
    manager = CheckpointManager(checkpoint_dir=checkpoint_dir)
    manager.clear_checkpoints()
    
    print("âœ“ æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹å·²æ¸…é™¤")
    logger.info("æ–­ç‚¹ç»­ä¼ æ£€æŸ¥ç‚¹å·²æ¸…é™¤")
    
    return 0


def run_once_mode(config: dict, logger: logging.Logger) -> int:
    """
    è¿è¡Œå•æ¬¡æ‰§è¡Œæ¨¡å¼
    Run once mode
    
    Args:
        config: é…ç½®å­—å…¸
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        é€€å‡ºç 
    """
    logger.info("å¯åŠ¨å•æ¬¡æ‰§è¡Œæ¨¡å¼...")
    
    try:
        scheduler = Scheduler(config)
        scheduler.run_once()
        logger.info("ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        return 0
    except Exception as e:
        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return 1


def run_evaluate_mode(config: dict, args: argparse.Namespace, logger: logging.Logger) -> int:
    """
    è¿è¡ŒRSSè¯„ä¼°æ¨¡å¼
    Run RSS evaluation mode
    
    Args:
        config: é…ç½®å­—å…¸
        args: å‘½ä»¤è¡Œå‚æ•°
        logger: æ—¥å¿—è®°å½•å™¨
    
    Returns:
        é€€å‡ºç 
    """
    logger.info("å¯åŠ¨RSSè¯„ä¼°æ¨¡å¼...")
    
    # å»¶è¿Ÿå¯¼å…¥è¯„ä¼°ç›¸å…³æ¨¡å—
    from src.analyzers.ai_analyzer import AIAnalyzer
    from src.evaluators.rss_evaluator import RSSEvaluator
    
    # ç¡®å®šOPMLæ–‡ä»¶è·¯å¾„
    opml_path = args.opml
    if not opml_path:
        # ä»é…ç½®æ–‡ä»¶è¯»å–
        opml_path = config.get('sources', {}).get('rss', {}).get('opml_path', 'feeds.opml')
    
    opml_file = Path(opml_path)
    if not opml_file.exists():
        logger.error(f"OPMLæ–‡ä»¶ä¸å­˜åœ¨: {opml_path}")
        print(f"é”™è¯¯: OPMLæ–‡ä»¶ä¸å­˜åœ¨: {opml_path}", file=sys.stderr)
        return 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ£€æŸ¥AIé…ç½®
    ai_config = config.get('ai', {})
    if not ai_config.get('api_key'):
        logger.warning("æœªé…ç½®AI APIå¯†é’¥ï¼Œè¯„ä¼°åŠŸèƒ½å¯èƒ½å—é™")
        print("è­¦å‘Š: æœªé…ç½®AI APIå¯†é’¥ (OPENAI_API_KEY)ï¼Œè¯„ä¼°åŠŸèƒ½å¯èƒ½å—é™", file=sys.stderr)
    
    try:
        # åˆå§‹åŒ–AIåˆ†æå™¨
        ai_analyzer = AIAnalyzer(ai_config)
        logger.info("AIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # åˆå§‹åŒ–RSSè¯„ä¼°å™¨
        evaluator_config = {
            'min_quality_score': args.min_score,
            'proxy': config.get('proxy', {}).get('url') if config.get('proxy', {}).get('enabled') else None,
            'timeout': ai_config.get('timeout', 30)
        }
        evaluator = RSSEvaluator(ai_analyzer, evaluator_config)
        logger.info("RSSè¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–è¯„ä¼°å™¨å¤±è´¥: {e}")
        print(f"é”™è¯¯: åˆå§‹åŒ–è¯„ä¼°å™¨å¤±è´¥: {e}", file=sys.stderr)
        return 1
    
    # æ‰“å°è¯„ä¼°ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"RSSè®¢é˜…æºè´¨é‡è¯„ä¼°")
    print(f"{'='*60}")
    print(f"OPMLæ–‡ä»¶: {opml_file.resolve()}")
    print(f"æœ€ä½è¯„åˆ†é˜ˆå€¼: {args.min_score}")
    print(f"è¾“å‡ºç›®å½•: {output_dir.resolve()}")
    print(f"{'='*60}\n")
    
    try:
        # æ‰§è¡Œè¯„ä¼°
        evaluations = evaluator.evaluate_all_feeds(str(opml_path))
        
        if not evaluations:
            logger.warning("æ²¡æœ‰è·å–åˆ°ä»»ä½•è¯„ä¼°ç»“æœ")
            print("è­¦å‘Š: æ²¡æœ‰è·å–åˆ°ä»»ä½•è¯„ä¼°ç»“æœ", file=sys.stderr)
            return 1
        
        # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
        report_path = output_dir / 'evaluation_report.md'
        report = evaluator.generate_report(evaluations)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        logger.info(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        print(f"âœ“ è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # å¯¼å‡ºç­›é€‰åçš„OPML
        filtered_opml_path = output_dir / 'filtered_feeds.opml'
        kept_count = evaluator.export_filtered_opml(
            evaluations,
            str(filtered_opml_path),
            min_score=args.min_score
        )
        logger.info(f"ç­›é€‰åçš„OPMLå·²ä¿å­˜: {filtered_opml_path}")
        print(f"âœ“ ç­›é€‰åçš„OPMLå·²ä¿å­˜: {filtered_opml_path}")
        
        # æ‰“å°æ‘˜è¦ç»Ÿè®¡
        total = len(evaluations)
        active_count = sum(1 for e in evaluations if e.is_active)
        keep_count = sum(1 for e in evaluations if e.recommendation == 'keep')
        remove_count = sum(1 for e in evaluations if e.recommendation == 'remove')
        review_count = sum(1 for e in evaluations if e.recommendation == 'review')
        avg_score = sum(e.quality_score for e in evaluations) / total if total > 0 else 0
        
        print(f"\n{'='*60}")
        print(f"è¯„ä¼°å®Œæˆ - æ‘˜è¦ç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æ€»è®¢é˜…æºæ•°: {total}")
        print(f"æ´»è·ƒè®¢é˜…æº: {active_count} ({active_count/total*100:.1f}%)" if total > 0 else "æ´»è·ƒè®¢é˜…æº: 0")
        print(f"å¹³å‡è´¨é‡è¯„åˆ†: {avg_score:.2f}")
        print(f"")
        print(f"æ¨èæ“ä½œ:")
        print(f"  âœ… ä¿ç•™: {keep_count}")
        print(f"  âš ï¸  å®¡æ ¸: {review_count}")
        print(f"  âŒ ç§»é™¤: {remove_count}")
        print(f"")
        print(f"ç­›é€‰åä¿ç•™: {kept_count} ä¸ªè®¢é˜…æº (è¯„åˆ† >= {args.min_score})")
        print(f"{'='*60}\n")
        
        logger.info(f"è¯„ä¼°å®Œæˆ: æ€»è®¡ {total} ä¸ªè®¢é˜…æº, ä¿ç•™ {kept_count} ä¸ª")
        return 0
        
    except Exception as e:
        logger.error(f"è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}", exc_info=True)
        print(f"é”™è¯¯: è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}", file=sys.stderr)
        return 1


def main() -> int:
    """
    ä¸»å‡½æ•°
    Main function
    
    Returns:
        é€€å‡ºç ï¼š0è¡¨ç¤ºæˆåŠŸï¼Œé0è¡¨ç¤ºå¤±è´¥
        Exit code: 0 for success, non-zero for failure
    
    **éªŒè¯: éœ€æ±‚ 7.5**
    """
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # é…ç½®æ—¥å¿—
    setup_logging(args.verbose)
    logger = logging.getLogger(__name__)
    
    # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆç¡®ä¿ç›¸å¯¹è·¯å¾„æ­£ç¡®ï¼‰
    os.chdir(project_root)
    logger.debug(f"å·¥ä½œç›®å½•: {project_root}")
    
    # éªŒè¯é…ç½®æ–‡ä»¶å­˜åœ¨
    config_path = Path(args.config)
    if not config_path.exists():
        logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}")
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config}", file=sys.stderr)
        return 1
    
    # åŠ è½½é…ç½®
    try:
        config = load_config(str(config_path), args.env)
        logger.info(f"å·²åŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        print(f"é”™è¯¯: åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}", file=sys.stderr)
        return 1
    
    # æ ¹æ®è¿è¡Œæ¨¡å¼æ‰§è¡Œç›¸åº”é€»è¾‘
    if args.checkpoint_status:
        # æŸ¥çœ‹æ–­ç‚¹çŠ¶æ€
        return show_checkpoint_status(config, logger)
    elif args.clear_checkpoint:
        # æ¸…é™¤æ–­ç‚¹
        return clear_checkpoint(config, logger)
    elif args.evaluate:
        # RSSè¯„ä¼°æ¨¡å¼
        return run_evaluate_mode(config, args, logger)
    elif args.once:
        # å•æ¬¡æ‰§è¡Œæ¨¡å¼
        return run_once_mode(config, logger)
    else:
        # å®šæ—¶è°ƒåº¦æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        return run_scheduled_mode(config, logger)


if __name__ == '__main__':
    sys.exit(main())
